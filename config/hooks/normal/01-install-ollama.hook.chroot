#!/bin/sh
set -e

# 1. Install Ollama
echo "Installing Ollama..."
curl -fsSL https://ollama.com/install.sh | sh

# 2. Configure Privy Shell
echo "Configuring Privy Shell..."
if ! grep -q "/usr/local/bin/privy" /etc/shells; then
    echo "/usr/local/bin/privy" >> /etc/shells
fi

# Force system-wide default shell for new users (fixes Calamares/Installer ignoring users.conf)
# Strategy: Comment out any existing definition and append our own to ensure it takes precedence.
if [ -f /etc/adduser.conf ]; then
    sed -i 's|^DSHELL=.*|#DSHELL=modified_by_privy_hook|' /etc/adduser.conf
    echo "DSHELL=/usr/local/bin/privy" >> /etc/adduser.conf
fi

if [ -f /etc/default/useradd ]; then
    sed -i 's|^SHELL=.*|#SHELL=modified_by_privy_hook|' /etc/default/useradd
    echo "SHELL=/usr/local/bin/privy" >> /etc/default/useradd
else
    echo "SHELL=/usr/local/bin/privy" > /etc/default/useradd
fi

chmod +x /usr/local/bin/privy
if [ -f /lib/live/config/9999-privy-shell ]; then
    chmod +x /lib/live/config/9999-privy-shell
fi

chsh -s /usr/local/bin/privy root

# 3. Configure Performance & Services
echo "Configuring System Services..."
# CPU Governor
echo 'GOVERNOR="performance"' > /etc/default/cpufrequtils

# Enable services
systemctl enable ollama
systemctl enable magic-network
systemctl enable cpufrequtils

# 3b. Configure Persistent Ollama Environment (CRITICAL FOR OFFLINE MODEL)
echo "Configuring persistent Ollama environment paths..."
mkdir -p /etc/systemd/system/ollama.service.d
cat <<EOF > /etc/systemd/system/ollama.service.d/environment.conf
[Service]
Environment="OLLAMA_MODELS=/usr/share/ollama/.ollama"
EOF

# 4. Pre-download Model
echo "Starting Ollama to pull model (qwen2.5-coder:1.5b)..."

# Create the directory where the systemd service expects models
mkdir -p /usr/share/ollama/.ollama
chown ollama:ollama /usr/share/ollama/.ollama

# Set environment variable so the build-time server writes to the correct place
export OLLAMA_MODELS="/usr/share/ollama/.ollama"

# Run ollama serve in background
ollama serve > /var/log/ollama_build.log 2>&1 &
PID=$!

# Wait for it to respond
tries=0
while [ $tries -lt 30 ]; do
    if curl -s http://localhost:11434/api/tags >/dev/null; then
        echo "Ollama is up."
        break
    fi
    echo "Waiting for Ollama ($tries)..."
    sleep 2
    tries=$((tries+1))
done

if [ $tries -lt 30 ]; then
    echo "Pulling model..."
    ollama pull qwen2.5-coder:1.5b
    
    # CRITICAL: Fix permissions so the 'ollama' user can read these files at runtime
    echo "Fixing permissions for Ollama models..."
    chown -R ollama:ollama /usr/share/ollama
    chmod -R 755 /usr/share/ollama
else
    echo "WARNING: Ollama did not start in time. Model not pulled."
    cat /var/log/ollama_build.log
fi

echo "Stopping Ollama..."
kill $PID || true
wait $PID || true