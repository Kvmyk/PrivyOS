#!/usr/bin/env python3
import sys
import os
import subprocess
import requests
import json
import time
import re

# Try importing rich for UI Polish
try:
    from rich.console import Console
    from rich.markdown import Markdown
    from rich.panel import Panel
    from rich.style import Style
    from rich.text import Text
    console = Console()
    HAS_RICH = True
except ImportError:
    HAS_RICH = False

# Konfiguracja
MODEL = "qwen2.5-coder:1.5b"
OLLAMA_API = "http://localhost:11434/api/generate"
OLLAMA_CHECK = "http://localhost:11434/api/tags"
HISTORY_LIMIT = 5

# Fallback Colors
CYAN = "\033[96m"
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
RESET = "\033[0m"

def print_styled(text, style="white"):
    if HAS_RICH:
        console.print(text, style=style)
    else:
        # Basic mapping
        color = RESET
        if style == "cyan": color = CYAN
        elif style == "green": color = GREEN
        elif style == "red": color = RED
        elif style == "yellow": color = YELLOW
        print(f"{color}{text}{RESET}")

def check_ollama_ready():
    """Sprawdza czy Ollama działa i czy model jest pobrany"""
    print_styled(f"[System] Inicjalizacja silnika AI...", "yellow")
    max_retries = 30
    for _ in range(max_retries):
        try:
            r = requests.get(OLLAMA_CHECK)
            if r.status_code == 200:
                models = [m['name'] for m in r.json()['models']]
                if MODEL not in models and f"{MODEL}:latest" not in models:
                    print_styled(f"[System] Model {MODEL} nie znaleziony. Pobieranie...", "red")
                    subprocess.run(f"ollama pull {MODEL}", shell=True)
                return True
        except:
            time.sleep(2)
    return False

def detect_intent(query):
    """Simple keyword routing to decide between System Admin and Coder mode"""
    code_keywords = [
        "write code", "create script", "generate file", "napisz kod", "stwórz plik", 
        "napisz skrypt", "program in", "python script", "bash script", "html file"
    ]
    query_lower = query.lower()
    for kw in code_keywords:
        if kw in query_lower:
            return "coder"
    return "admin"

def process_ai_interaction(user_query, history):
    intent = detect_intent(user_query)
    
    # RAG: Search local documentation
    local_context = ""
    try:
        rag_res = subprocess.run(["privy-rag", user_query], capture_output=True, text=True)
        if rag_res.stdout.strip():
            local_context = f"\nLOCAL SYSTEM DOCUMENTATION:\n{rag_res.stdout}\n"
    except:
        pass

    # Build Context History
    context_str = ""
    if history:
        context_str = "PREVIOUS CONTEXT:\n"
        for item in history:
            context_str += f"User: {item['user']}\nLast Command: {item['cmd']}\nResult: {item['status']}\n---\n"

    # Base System Prompts
    if intent == "coder":
        system_instruction = f"You are a Coding Assistant. Generate BASH commands to CREATE files using 'cat << EOF'.\n{local_context}\nOUTPUT ONLY THE BASH COMMAND. No explanations."
    else:
        system_instruction = f"""You are PrivyOS System Assistant.
        {local_context}
        MODES:
        1. **QUERY/INFO** (User asks "What is...", "Check...", "Show me..."):
           - You can run read-only commands silently to get info.
           - FORMAT: `[[CHECK: command]]`
           - IMPORTANT: After receiving "TOOL OUTPUT", you MUST provide a human-readable summary. DO NOT loop unless the previous command failed.

        2. **ACTION** (User asks "Create...", "Delete...", "Move...", "Install..."):
           - Output the BASH command directly.
           - Do NOT use markdown.

        EXAMPLE FLOW:
        User: "How much RAM is free?"
        Assistant: [[CHECK: free -h]]
        System: TOOL OUTPUT: Mem: 16Gi 8Gi 8Gi ...
        Assistant: You have 8Gi of free RAM.

        3. **CHAT**:
           - Just reply nicely.
        """

    messages = [
        {"role": "system", "content": system_instruction},
        {"role": "user", "content": f"{context_str}\nUser Request: {user_query}"}
    ]

    # Tool Use Loop (Increased to 4 to allow retry)
    for _ in range(4):
        try:
            # Prepare prompt for non-chat API (using raw prompt mode for simplicity with this model)
            # Or construct a chat-like structure if the model supports it better. 
            # Qwen2.5-Coder handles raw text well.
            
            conversation = ""
            for m in messages:
                conversation += f"{m['role'].upper()}: {m['content']}\n"
            conversation += "ASSISTANT:"

            response = requests.post(OLLAMA_API, json={
                "model": MODEL,
                "prompt": conversation,
                "stream": False,
                "options": {"temperature": 0.1, "num_ctx": 4096}
            })
            if response.status_code != 200:
                return {"type": "error", "content": f"API Error: {response.status_code}"}
            
            raw_output = response.json()['response'].strip()
            
            # 1. Check for Tool Use ([[CHECK: ...]])
            check_match = re.search(r"\[\[CHECK:\s*(.*?)\]\]", raw_output, re.IGNORECASE)
            if check_match:
                cmd_to_run = check_match.group(1).strip()
                print_styled(f"[Agent] Sprawdzam: {cmd_to_run}...", "yellow")
                
                # Execute silently
                try:
                    # Timeout to prevent hanging
                    proc = subprocess.run(cmd_to_run, shell=True, capture_output=True, text=True, timeout=5)
                    tool_output = proc.stdout[:2000] + proc.stderr[:500] # Limit output size
                    if not tool_output.strip(): tool_output = "(No output)"
                except subprocess.TimeoutExpired:
                    tool_output = "Error: Command timed out."
                except Exception as e:
                    tool_output = f"Error executing check: {e}"

                # Add result to conversation and loop again
                messages.append({"role": "assistant", "content": raw_output})
                messages.append({"role": "system", "content": f"TOOL OUTPUT for '{cmd_to_run}':\n{tool_output}\n\nNow answer the user's question based on this info."})
                continue
            
            # 2. Cleanup Markdown for final output
            final_cmd = raw_output
            if final_cmd.startswith("```"):
                lines = final_cmd.splitlines()
                if len(lines) >= 3:
                    final_cmd = "\n".join(lines[1:-1])
                else:
                    final_cmd = final_cmd.replace("```bash", "").replace("```", "")
            final_cmd = final_cmd.strip()

            # 3. Decide if it's a Command (Action) or Message (Answer)
            # Heuristic: If it looks like a bash command (starts with common utils or contains operators) -> Suggestion
            # If it's natural language -> Message
            
            # Simple heuristic: specific chars or length. 
            # Better: if intent was 'coder', it's always code.
            # If it contains spaces and reads like a sentence, it's a message.
            
            is_command = False
            if intent == "coder":
                is_command = True
            else:
                # Common commands start
                common_bins = ["ls", "cd", "cat", "grep", "find", "mkdir", "rm", "mv", "cp", "git", "apt", "nano", "vim", "python", "curl", "wget", "ip", "ping", "systemctl", "sudo"]
                first_word = final_cmd.split()[0] if final_cmd else ""
                if first_word in common_bins or "&&" in final_cmd or "|" in final_cmd or "=" in final_cmd:
                    is_command = True
                
                # If it has newlines and doesn't look like a script, it might be a long explanation
                if "\n" in final_cmd and not ("&&" in final_cmd or ";" in final_cmd):
                     is_command = False

            if is_command:
                return {"type": "suggestion", "content": final_cmd}
            else:
                return {"type": "message", "content": raw_output.replace("[[CHECK:", "").strip()} # Clean up if it hallucinated partial tag

        except Exception as e:
            return {"type": "error", "content": f"Logic Error: {e}"}

    return {"type": "error", "content": "Agent loop limit reached."}

def print_banner():
    if HAS_RICH:
        title = """
    ____       _            ____  _____ 
   / __ \_____(_)   ___  __/ __ \/ __ \ 
  / /_/ / ___/ / | / / / / / / /\__ \ 
 / ____/ /  / /| |/ / /_/ / /_/ /__/ / 
/_/   /_/  /_/ |___/\__, /\____/____/  
                   /____/              
"""
        panel = Panel(
            Text(title, style="cyan bold") + Text("\nPrivyOS v1.4 - Local AI Terminal", style="white"),
            border_style="cyan"
        )
        console.print(panel)
    else:
        print(f"{CYAN}PrivyOS v1.4{RESET}")

def main():
    os.system('clear')
    print_banner()

    ai_enabled = True
    if not check_ollama_ready():
        print_styled("OSTRZEŻENIE: System AI nie odpowiada. Przełączono w tryb awaryjny (tylko komendy natywne).", "red")
        print_styled("Spróbuj: systemctl restart ollama", "yellow")
        ai_enabled = False

    NATIVE_COMMANDS = [
        'ls', 'cd', 'pwd', 'cat', 'more', 'less', 'grep', 'cp', 'mv', 'rm', 
        'mkdir', 'rmdir', 'touch', 'nano', 'vim', 'vi', 'sudo', 'su', 
        'whoami', 'id', 'ip', 'ifconfig', 'ping', 'top', 'htop', 'free', 
        'df', 'du', 'ps', 'kill', 'killall', 'reboot', 'poweroff', 'shutdown', 
        'clear', 'history', 'exit', 'logout', 'man', 'help', 'python', 'python3',
        'systemctl', 'journalctl', 'privy-status', 'privypm'
    ]

    history = []

    while True:
        try:
            cwd = os.getcwd()
            # Input Prompt
            prompt_color = GREEN if ai_enabled else RED
            mode_str = "" if ai_enabled else " [OFFLINE]"
            
            if HAS_RICH:
                p_style = "\033[92m" if ai_enabled else "\033[91m"
                user_input = input(f"{p_style}PrivyOS{mode_str} \033[96m{cwd}\033[0m > ")
            else:
                user_input = input(f"{prompt_color}PrivyOS{mode_str} {CYAN}{cwd}{RESET} > ")
            
            if not user_input.strip(): continue
            if user_input.lower() in ['exit', 'logout']: break
            
            cmd_root = user_input.split()[0]
            
            # Native Commands
            if cmd_root in NATIVE_COMMANDS:
                if cmd_root == 'cd':
                    path = user_input[3:].strip()
                    if not path: path = os.path.expanduser('~')
                    if path.startswith('~'): path = os.path.expanduser(path)
                    try:
                        os.chdir(path)
                        if len(history) >= HISTORY_LIMIT: history.pop(0)
                        history.append({'user': user_input, 'cmd': f"cd {path}", 'status': 'Success'})
                    except Exception as e:
                        print_styled(f"Error: {e}", "red")
                else:
                    ret = os.system(user_input)
                    status = "Success" if ret == 0 else "Failed"
                    if len(history) >= HISTORY_LIMIT: history.pop(0)
                    history.append({'user': user_input, 'cmd': user_input, 'status': status})
                continue

            # AI Command logic
            if not ai_enabled:
                print_styled("Błąd: AI niedostępne. Użyj komend natywnych lub napraw Ollamę.", "red")
                continue

            print("Thinking...", end="\r")
            result = process_ai_interaction(user_input, history)
            print(" " * 20, end="\r")
            
            if result['type'] == 'message':
                # AI responded with text (after potentially running checks)
                if HAS_RICH:
                     console.print(Panel(Markdown(result['content']), title="AI Assistant", border_style="blue"))
                else:
                     print(f"{CYAN}{result['content']}{RESET}")
                
                # Add to history as interaction
                if len(history) >= HISTORY_LIMIT: history.pop(0)
                history.append({'user': user_input, 'cmd': "(Chat/Info)", 'status': "Replied"})

            elif result['type'] == 'suggestion':
                # AI suggested a command to run
                cmd = result['content']
                if HAS_RICH:
                    console.print(Panel(Text(cmd, style="green"), title="AI Suggestion", border_style="green"))
                else:
                    print(f"Sugestia: {CYAN}{cmd}{RESET}")

                confirm = input("Wykonać? [Y/n]: ")
                
                if confirm.lower() in ['y', '']:
                    if cmd.startswith("cd "):
                         try:
                            os.chdir(cmd[3:].strip())
                            status = "Success"
                         except:
                            status = "Failed"
                    else:
                        try:
                            proc_res = subprocess.run(cmd, shell=True)
                            status = "Success" if proc_res.returncode == 0 else "Failed"
                        except Exception as e:
                             print_styled(f"Error: {e}", "red")
                             status = f"Error: {e}"
                    
                    if len(history) >= HISTORY_LIMIT: history.pop(0)
                    history.append({'user': user_input, 'cmd': cmd, 'status': status})
            
            elif result['type'] == 'error':
                 print_styled(f"AI Error: {result['content']}", "red")

        except KeyboardInterrupt:
            print("\nUżyj 'exit' aby wyjść.")

if __name__ == "__main__":
    main()
